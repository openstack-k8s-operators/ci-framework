---
# Copyright Red Hat, Inc.
# All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

- name: Converge
  hosts: instance
  vars:
    ansible_user_dir: "{{ lookup('env', 'HOME') }}"
    cifmw_basedir: "{{ ansible_user_dir }}/ci-framework-data"
  tasks:
    - name: Crate SSH keypair
      register: _test_key
      community.crypto.openssh_keypair:
        comment: "test-key"
        path: "{{ (ansible_user_dir, '.ssh/id_test') | path_join }}"
        type: "ecdsa"

    - name: Enable forwarding in the libvirt zone
      become: true
      ansible.builtin.command:
        cmd: >-
          firewall-cmd --permanent --zone libvirt --add-forward

    - name: Restart firewalld.service
      become: true
      ansible.builtin.systemd_service:
        name: firewalld
        state: restarted

    - name: Discover latest image
      when:
        - cifmw_discovered_image_url is not defined
      ansible.builtin.include_role:
        name: discover_latest_image

    - name: Download latest image
      ansible.builtin.get_url:
        url: "{{ cifmw_discovered_image_url }}"
        dest: "{{ cifmw_basedir }}"
        timeout: 20
      register: result
      until: result is success
      retries: 60
      delay: 10

    - name: Build nat64 appliance image
      vars:
        # TODO(hjensas): Running as root should not be required here.
        #  But the CI job fails with permission issue unless using root.
        #  This permission error is only seen in CI and when using the
        #  ci-framework reproducer.
        cifmw_nat64_appliance_run_dib_as_root: true
      ansible.builtin.include_role:
        name: nat64_appliance

    - name: Fix permissions on logs dir - because we ran dib as root
      become: true
      ansible.builtin.file:
        path: "{{ cifmw_basedir }}/logs"
        state: directory
        recurse: true
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"

    - name: Fix permissions on nat64_appliance dir - because we ran dib as root
      become: true
      ansible.builtin.file:
        path: "{{ cifmw_basedir }}/nat64_appliance"
        state: directory
        recurse: true
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"

    - name: "Deploy the nat64 appliance and networks"
      vars:
        cifmw_nat64_appliance_ssh_pub_keys:
          - "{{ _test_key.public_key }}"
      ansible.builtin.include_role:
        name: nat64_appliance
        tasks_from: deploy.yml

    - name: Set MAC address facts
      ansible.builtin.set_fact:
        test_node_mac_address: "{{ '52:54:00' | community.general.random_mac }}"

    - name: Define a IPv6 network for test node
      community.libvirt.virt_net:
        command: define
        name: br-mol
        xml: |-
          <network>
            <name>br-mol</name>
            <forward mode='open'/>
            <bridge name='br-mol' zone='libvirt' stp='on' delay='0'/>
            <ip family='ipv6' address='2620:cf:cf:aaaa::1' prefix='64'/>
            <dns>
              <forwarder addr='2620:cf:cf:fc00::2'/>
            </dns>
          </network>
        uri: 'qemu:///system'

    - name: Create a IPv6 network for test node
      community.libvirt.virt_net:
        command: create
        name: br-mol
        uri: 'qemu:///system'

    - name: Ensure the IPv6 network for test node is active
      community.libvirt.virt_net:
        state: active
        name: br-mol
        uri: 'qemu:///system'

    - name: Ensure the IPv6 network for test node is enabled to autostart
      community.libvirt.virt_net:
        autostart: true
        name: br-mol
        uri: 'qemu:///system'

    # TODO(hjensas): With the zone set in libvirt XML this bridge "should"
    # already be in this zone. But logs indicate that it is not.
    # See: https://libvirt.org/formatnetwork.html
    - name: Make sure br-mol bridge is in the libvirt firewalld zone
      become: true
      ansible.posix.firewalld:
        zone: libvirt
        interface: br-mol
        state: enabled
        permanent: true

    - name: Restart firewalld.service
      become: true
      ansible.builtin.systemd_service:
        name: firewalld
        state: restarted

    - name: Generate test node UUID
      ansible.builtin.set_fact:
        test_node_uuid: "{{ 99999999 | random | to_uuid | lower }}"

    - name: Make an a copy of the discovered/downloaded image
      ansible.builtin.copy:
        src: "{{ cifmw_basedir }}/{{ cifmw_discovered_image_name }}"
        dest: "{{ cifmw_basedir }}/{{ test_node_uuid }}.qcow2"
        owner: "{{ ansible_user_id }}"
        group: "{{ ansible_user_gid }}"
        mode: '0644'

    - name: Create the config-drive ISO for the test node
      vars:
        cifmw_config_drive_iso_image: "{{ cifmw_basedir }}/{{ test_node_uuid }}.iso"
        cifmw_config_drive_uuid: "{{ test_node_uuid }}"
        cifmw_config_drive_name: mol-test-node
        cifmw_config_drive_hostname: mol-test-node
        cifmw_config_drive_userdata:
          ssh_authorized_keys:
            - "{{ _test_key.public_key }}"
        cifmw_config_drive_networkconfig:
          network:
            version: 2
            ethernets:
              id0:
                match:
                  macaddress: "{{ test_node_mac_address }}"
                addresses:
                  - '2620:cf:cf:aaaa::101/64'
                routes:
                  - to: '::/0'
                    via: '2620:cf:cf:aaaa::1'
                    on-link: true
                nameservers:
                  addresses:
                    - '2620:cf:cf:aaaa::1'
      ansible.builtin.include_role:
        name: config_drive

    - name: Define test-node VM
      community.libvirt.virt:
        command: define
        xml: |
          <domain type='kvm'>
            <name>test-node</name>
            <uuid>{{ test_node_uuid }}</uuid>
            <memory unit='GB'>1</memory>
            <vcpu placement='static'>2</vcpu>
            <os>
              <type arch='x86_64' machine='q35'>hvm</type>
              <boot dev='hd'/>
              <bootmenu enable='no'/>
            </os>
            <cpu mode='host-passthrough' check='none'/>
            <clock offset='utc'>
              <timer name='rtc' tickpolicy='catchup'/>
              <timer name='pit' tickpolicy='delay'/>
              <timer name='hpet' present='no'/>
            </clock>
            <features>
              <acpi/>
              <apic/>
            </features>
            <devices>
              <emulator>/usr/libexec/qemu-kvm</emulator>
              <disk type='file' device='disk'>
                <driver name='qemu' type='qcow2'/>
                <source file='{{ cifmw_basedir }}/{{ test_node_uuid }}.qcow2'/>
                <target dev='vda' bus='virtio'/>
              </disk>
              <disk type='file' device='cdrom'>
                <driver name='qemu' type='raw'/>
                <source file='{{ cifmw_basedir }}/{{ test_node_uuid }}.iso'/>
                <target dev='sdb' bus='sata'/>
                <readonly/>
              </disk>
              <controller type='pci' index='0' model='pcie-root'>
                <alias name='pci.0'/>
              </controller>
              <controller type='virtio-serial' index='0'>
                <alias name='virtio-serial0'/>
                <address type='pci'/>
              </controller>
              <interface type='network'>
                <mac address='{{ test_node_mac_address }}'/>
                <source network='br-mol'/>
                <model type='virtio'/>
                <address type='pci' domain='0x0000' bus='0x01' slot='0x00' function='0x0'/>
              </interface>
              <serial type='pty'>
                <source path='/dev/pts/1'/>
                <log file="/var/log/libvirt/qemu/{{ test_node_uuid }}-serial.log" append="off"/>
                <target type='isa-serial' port='0'>
                  <model name='isa-serial'/>
                </target>
                <alias name='serial0'/>
              </serial>
              <console type='pty' tty='/dev/pts/1'>
                <log file="/var/log/libvirt/qemu/{{ test_node_uuid }}-console.log" append="off"/>
                <source path='/dev/pts/1'/>
                <target type='serial' port='0'/>
                <alias name='serial0'/>
              </console>
              <input type='mouse' bus='ps2'>
                <alias name='input1'/>
              </input>
              <input type='keyboard' bus='ps2'>
                <alias name='input2'/>
              </input>
              <video>
                <model type='virtio' vram='16384' heads='1' primary='yes'/>
                <alias name='video0'/>
                <address type='pci'/>
              </video>
              <memballoon model='virtio'>
                <alias name='balloon0'/>
                <address type='pci'/>
              </memballoon>
              <rng model='virtio'>
                <backend model='random'>/dev/urandom</backend>
                <rate bytes="1024" period="100"/>
                <alias name='rng0'/>
                <address type='pci'/>
              </rng>
            </devices>
            <on_poweroff>destroy</on_poweroff>
            <on_reboot>restart</on_reboot>
            <on_crash>destroy</on_crash>
            <pm>
              <suspend-to-mem enabled='no'/>
              <suspend-to-disk enabled='no'/>
            </pm>
          </domain>
        uri: 'qemu:///system'

    - name: Start test-node VM
      community.libvirt.virt:
        state: running
        name: test-node
        uri: 'qemu:///system'

    - name: Wait for test node to be reachable via ssh
      ansible.builtin.wait_for:
        host: '2620:cf:cf:aaaa::101'
        port: 22
        state: present
        delay: 10

    - name: Add test node to inventory
      ansible.builtin.add_host:
        name: test-node
        groups:
          - testnodes
        ansible_host: '2620:cf:cf:aaaa::101'
        ansible_ssh_user: 'cloud-user'
        ansible_ssh_private_key_file: "{{ _test_key.filename }}"
        ansible_ssh_extra_args: '-o StrictHostKeyChecking=no'

    - name: Add nat64 appliance to the invetory
      ansible.builtin.add_host:
        name: nat64-appliance
        groups:
          - nat64appliances
        ansible_host: '172.31.255.2'
        ansible_ssh_user: 'cloud-user'
        ansible_ssh_private_key_file: "{{ _test_key.filename }}"
        ansible_ssh_extra_args: '-o StrictHostKeyChecking=no'

    # Even tough the node respond on port 22, let some time to ensure
    # ssh access for users is available.
    - name: Wait a little to let the test instance boot.
      ansible.builtin.pause:
        seconds: 20

    - name: Run some commands to test the nat64-appliance DNS64 functions
      register: _nat64_appliance_dns64_debug
      ansible.builtin.shell: |
        echo "--- ping the DNS service listening address ---"
        ping -c 4 2620:cf:cf:fc00::2 || true
        echo
        echo "--- Try to resolve a name using 2620:cf:cf:fc00::2 ---"
        dig AAAA @2620:cf:cf:fc00::2 example.com
        echo
        echo "--- Try to resolve a name forwarding on test-network 2620:cf:cf:aaaa::1 ---"
        dig AAAA @2620:cf:cf:aaaa::1 example.com
        echo
        echo "--- Try to ping exmaple.com ---"
        ping -c 4 example.com || true

    - name: Grab some info from the test node
      become: true
      delegate_to: test-node
      register: _test_node_debug_info
      ansible.builtin.shell: |
        echo "--- ip addr show ---"
        ip addr show
        echo
        echo "--- ip -6 route show ---"
        ip -6 route show
        echo
        echo "--- /etc/resolv.conf ---"
        cat /etc/resolv.conf
        echo
        echo "--- NetworkManager system-connections ---"
        for file in $(find /etc/NetworkManager/system-connections/ -type f); do
          echo "--- $file ---"
          cat $file
          echo
        done

    - name: Grab some info from the nat64 appliance
      become: true
      delegate_to: nat64-appliance
      register: _nat64_appliance_debug_info
      ansible.builtin.shell: |
        echo "--- ip addr show ---"
        ip addr show
        echo
        echo "--- ip -4 route show ---"
        ip -4 route show
        echo
        echo "--- ip -6 route show ---"
        ip -6 route show
        echo
        echo "--- /etc/resolv.conf ---"
        cat /etc/resolv.conf
        echo
        echo "--- NetworkManager system-connections ---"
        for file in $(find /etc/NetworkManager/system-connections/ -type f); do
          echo "--- $file ---"
          cat $file
          echo
        done
        echo
        echo "--- systemctl status unbound.service ---"
        systemctl status unbound.service
        echo
        echo "--- systemctl status nat64-v4-dnsmasq.service ---"
        systemctl status nat64-v4-dnsmasq.service
        echo
        echo "--- systemctl status nat64-v6-dnsmasq.service ---"
        systemctl status nat64-v6-dnsmasq.service

    - name: Grab the journal from the nat64 appliance
      become: true
      delegate_to: nat64-appliance
      register: _nat64_appliance_journal
      ansible.builtin.shell: |
        journalctl -b --no-pager

    - name: Grab some info from hypervisor
      become: true
      delegate_to: instance
      register: _hypervisor_info
      ansible.builtin.shell: |
        echo "--- ip addr show ---"
        ip addr show
        echo
        echo "--- ip -4 route show ---"
        ip -4 route show
        echo
        echo "--- ip -6 route show ---"
        ip -6 route show
        echo
        echo "--- firewall - list-all-zones"
        firewall-cmd --list-all-zones
        echo
        echo "--- sysctl - list all"
        sysctl -a

    - name: Write test-node info to file
      ansible.builtin.copy:
        dest: "{{ cifmw_basedir }}/logs/test_node_info.log"
        content: "{{ _test_node_debug_info.stdout }}"

    - name: Write nat64-appliance info to file
      ansible.builtin.copy:
        dest: "{{ cifmw_basedir }}/logs/nat64_appliance_node_info.log"
        content: "{{ _nat64_appliance_debug_info.stdout }}"

    - name: Write nat64-appliance journal to file
      ansible.builtin.copy:
        dest: "{{ cifmw_basedir }}/logs/nat64_appliance_journal.log"
        content: "{{ _nat64_appliance_journal.stdout }}"

    - name: Write nat64-appliance DNS64 debug to file
      ansible.builtin.copy:
        dest: "{{ cifmw_basedir }}/logs/nat64_appliance_dns64_debug.log"
        content: "{{ _nat64_appliance_dns64_debug.stdout }}"

    - name: Write hypervisor info to file
      ansible.builtin.copy:
        dest: "{{ cifmw_basedir }}/logs/hypervisor_info.log"
        content: "{{ _hypervisor_info.stdout }}"

    - name: Ping example.com (delegate to test-node)
      delegate_to: test-node
      register: _ping_example_com
      ansible.builtin.command: "ping -c 2 example.com"
      until: _ping_example_com.rc == 0
      retries: 60
      delay: 10

    - name: Debug the ping example.com result
      ansible.builtin.debug:
        msg: "{{ item }}"
      loop:
        - "{{ _ping_example_com.rc }}"
        - "{{ _ping_example_com.stdout_lines }}"
        - "{{ _ping_example_com.stderr_lines }}"

    - name: "Run deploy nat64 appliance again, to test idempotency"
      vars:
        cifmw_nat64_appliance_ssh_pub_keys:
          - "{{ _test_key.public_key }}"
      ansible.builtin.include_role:
        name: nat64_appliance
        tasks_from: deploy.yml

    - name: Ping example.com (delegate to test-node) - post idempotency test
      delegate_to: test-node
      register: _ping_example_com
      ansible.builtin.command: "ping -c 2 example.com"
      until: _ping_example_com.rc == 0
      retries: 60
      delay: 10

    - name: Debug the ping example.com result - post idempotency test
      ansible.builtin.debug:
        msg: "{{ item }}"
      loop:
        - "{{ _ping_example_com.rc }}"
        - "{{ _ping_example_com.stdout_lines }}"
        - "{{ _ping_example_com.stderr_lines }}"
