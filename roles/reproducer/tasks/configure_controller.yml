---
- name: Set facts related to the reproducer
  ansible.builtin.set_fact:
    _ctl_reproducer_basedir: >-
      {{
        (
         '/home/zuul',
         'ci-framework-data',
         ) | path_join
      }}

# The dynamic inventory sets the ansible_ssh_user to zuul once we get the proper
# ssh configuration accesses set.
- name: Configure controller-0
  when:
    - (
        _cifmw_libvirt_manager_layout.vms.controller.target is defined and
        _cifmw_libvirt_manager_layout.vms.controller.target == inventory_hostname
      ) or
      _cifmw_libvirt_manager_layout.vms.controller.target is undefined
  delegate_to: controller-0
  delegate_facts: false
  vars:
    cifmw_sushy_emulator_basedir: "{{ _ctl_reproducer_basedir }}"
    cifmw_sushy_emulator_sshkey_path: >-
      {{
        [_ctl_reproducer_basedir, '../.ssh/sushy_emulator-key'] |
        path_join
      }}
    cifmw_podman_user_linger: "zuul"
    cifmw_sushy_emulator_libvirt_user: "{{ hostvars[cifmw_sushy_emulator_hypervisor_target].ansible_user_id | default('zuul') }}"
  block:
    - name: Ensure directories exist
      ansible.builtin.file:
        path: "{{ _ctl_reproducer_basedir }}/{{ item }}"
        state: directory
        mode: "0755"
      loop:
        - parameters
        - artifacts

    - name: Install custom CA if needed
      ansible.builtin.import_role:
        name: install_ca

    - name: RHEL repository setup for ansible-controller
      become: true
      when:
        - cifmw_repo_setup_rhos_release_rpm is defined
      block:
        - name: Get rhos-release
          ansible.builtin.import_tasks: rhos_release.yml

        - name: Create bundle for CRC
          ansible.builtin.shell:
            cmd: >-
              set -o pipefail;
              cat /etc/pki/ca-trust/source/anchors/* >
              /etc/pki/ca-trust/source/anchors/rh.crt
            creates: "/etc/pki/ca-trust/source/anchors/rh.crt"

    - name: Tweak dnf configuration
      become: true
      community.general.ini_file:
        no_extra_spaces: true
        option: "{{ config.option }}"
        path: "/etc/dnf/dnf.conf"
        section: "{{ config.section | default('main') }}"
        state: "{{ config.state | default(omit) }}"
        value: "{{ config.value | default(omit) }}"
      loop: "{{ cifmw_reproducer_dnf_tweaks }}"
      loop_control:
        label: "{{ config.option }}"
        loop_var: 'config'

    - name: Install some tools
      become: true
      async: 600  # 10 minutes should be enough
      poll: 0
      register: _async_pkg_install
      ansible.builtin.package:
        name:
          - bash-completion
          - bind-utils
          - git-core
          - make
          - podman
          - python3-jmespath
          - python3-netaddr
          - python3-pip
          - tmux
          - vim
          - wget
          - jq

    - name: Build job inventory for hook usage
      tags:
        - bootstrap
      ansible.builtin.shell:
        cmd: >-
          cat /home/zuul/reproducer-inventory/* >
          {{  _ctl_reproducer_basedir }}/artifacts/zuul_inventory.yml

    # You want to use the "name" parameter of the ansible.builtin.include_vars
    # call, such as:
    # - name: Load mac mapping
    #   ansible.builtin.include_vars:
    #     file: "{{ _ctl_reproducer_basedir }}/parameters/interfaces-info.yml"
    #     name: my_fancy_name
    # Then you'll be able to access the mapping content via `my_fancy_name`.
    - name: Push the MAC mapping data
      tags:
        - bootstrap
      when:
        - cifmw_libvirt_manager_mac_map is defined
      ansible.builtin.copy:
        dest: "{{ _ctl_reproducer_basedir }}/parameters/interfaces-info.yml"
        content: "{{ cifmw_libvirt_manager_mac_map | to_nice_yaml }}"

    - name: Inject other Hypervisor SSH keys
      when:
        - hostvars[host]['priv_ssh_key'] is defined
      vars:
        _ssh_key: "{{ hostvars[host]['priv_ssh_key']['content'] | b64decode }}"
        _ssh_host: >-
          {{
            hostvars[host]['ansible_host'] |
            default(hostvars[host]['inventory_hostname'])
          }}
      ansible.builtin.copy:
        dest: "/home/zuul/.ssh/ssh_{{ _ssh_host }}"
        content: "{{ _ssh_key }}"
        mode: "0600"
      loop: "{{ hostvars.keys() }}"
      loop_control:
        label: "{{ host }}"
        loop_var: "host"

    # We need to configure SSH on controller-0 so that
    # it will consume the right ssh key and not obsess on
    # remote host key checking. We have to put this in the
    # local .ssh/config, because ProxyJump doesn't take the
    # command line options, meaning ssh won't consume the various
    # options set in the ansible inventory.
    - name: Inject remote hypervisor SSH configuration
      when:
        - hostvars[host]['priv_ssh_key'] is defined
      vars:
        _ssh_host: >-
          {{
            hostvars[host]['ansible_host'] |
            default(hostvars[host]['inventory_hostname'])
          }}
      ansible.builtin.blockinfile:
        create: true
        path: "/home/zuul/.ssh/config"
        marker: "## {mark} {{ _ssh_host }}"
        block: |-
          Host {{ _ssh_host }} {{ hostvars[host]['inventory_hostname'] }}
            IdentityFile ~/.ssh/ssh_{{ _ssh_host }}
            StrictHostKeyChecking no
            UserKnownHostsFile /dev/null
            User {{ hostvars[host]['ansible_user'] | default(ansible_user_id) }}
      loop: "{{ hostvars.keys() }}"
      loop_control:
        label: "{{ host }}"
        loop_var: "host"

    - name: Inject ProxyJump configuration for remote hypervisor VMs
      when:
        - hostvars[host]['host_ip'] is defined
      vars:
        _vm_type: "{{ host | regex_replace('\\-[0-9]*', '') }}"
        _vm_data: "{{ _cifmw_libvirt_manager_layout.vms[_vm_type] }}"
        _proxy_user: >-
          {{
            (hostvars[_vm_data.target]['ansible_user'] |
            default(ansible_user_id)) |
            default('')
          }}
        _proxy_host: "{{ _vm_data.target | default('') }}"
        _ssh_host: >-
          {{
            (hostvars[_proxy_host]['ansible_host'] |
            default(hostvars[_proxy_host]['inventory_hostname'])) |
            default('')
          }}
        _vm_ip: "{{ hostvars[host]['ansible_host'] | default('')}}"
      ansible.builtin.blockinfile:
        path: "/home/zuul/.ssh/config"
        marker: "## {mark} {{ host }}"
        block: |-
          Host {{ host }} {{ _vm_ip }} {{ hostvars[host]['host_ip'] }}
            Hostname {{ hostvars[host]['host_ip'] }}
            User {{ _vm_data['admin_user'] | default('zuul') }}
            StrictHostKeyChecking no
            UserKnownHostsFile /dev/null
          {% if _vm_data.target is defined and
             _vm_data.target != _cifmw_libvirt_manager_layout.vms.controller.target %}
            IdentityFile ~/.ssh/ssh_{{ _ssh_host }}
            ProxyJump {{ _proxy_user }}@{{ _proxy_host }}
          {% elif host is match('^ocp.*') %}
            IdentityFile ~/.ssh/devscripts_key
          {% else %}
            IdentityFile ~/.ssh/id_cifw
          {% endif %}
      loop: "{{ hostvars.keys() }}"
      loop_control:
        loop_var: host
        label: "{{ host }}"

    - name: Create kube directory
      ansible.builtin.file:
        path: "/home/zuul/.kube"
        state: directory
        owner: zuul
        group: zuul
        mode: "0750"

    - name: Inject kubeconfig content
      when:
        - _devscripts_kubeconfig.content is defined or
          _crc_kubeconfig.content is defined
      ansible.builtin.copy:
        dest: "/home/zuul/.kube/config"
        content: >-
          {{
            (_cifmw_libvirt_manager_layout.vms.ocp is defined) |
            ternary(_devscripts_kubeconfig.content, _crc_kubeconfig.content) |
            b64decode
          }}
        owner: zuul
        group: zuul
        mode: "0640"

    - name: Inject kubeadmin-password if exists
      when:
        - _devscripts_kubeadm.content is defined or
          _crc_kubeadm.content is defined
      ansible.builtin.copy:
        dest: "/home/zuul/.kube/kubeadmin-password"
        content: >-
          {{
            (_devscripts_kubeadm.content is defined) |
            ternary(_devscripts_kubeadm.content, _crc_kubeadm.content) |
            b64decode
          }}
        owner: zuul
        group: zuul
        mode: "0600"

    - name: Inject devscripts private key if set
      when:
        - _devscript_privkey.content is defined
      ansible.builtin.copy:
        dest: "/home/zuul/.ssh/devscripts_key"
        content: "{{ _devscript_privkey.content | b64decode }}"
        owner: "zuul"
        group: "zuul"
        mode: "0400"

    - name: Ensure /etc/ci/env is created
      become: true
      ansible.builtin.file:
        path: /etc/ci/env
        state: directory
        mode: "0755"

    - name: Manage secrets on controller-0
      vars:
        cifmw_manage_secrets_basedir: "/home/zuul/ci-framework-data"
        cifmw_manage_secrets_owner: "zuul"
      block:
        - name: Initialize secret manager
          ansible.builtin.import_role:
            name: manage_secrets

        - name: Inject secrets
          ansible.builtin.import_role:
            name: manage_secrets
            tasks_from: reproducer.yml

    - name: Inject FQDN in /etc/hosts
      become: true
      ansible.builtin.blockinfile:
        dest: /etc/hosts
        block: |-
         127.0.0.2 {{ hostvars['controller-0'].ansible_host }}
         ::2 {{ hostvars['controller-0'].ansible_host }}

    - name: Ensure packages are installed
      become: true
      block:
        - name: Check if async file is still available
          register: _async_flag
          ansible.builtin.stat:
            path: >-
              /root/.ansible_async/{{ _async_pkg_install.ansible_job_id }}

        - name: Check package install status
          when:
            - _async_flag.stat.exists
          register: _async_status
          ansible.builtin.async_status:
            jid: "{{ _async_pkg_install.ansible_job_id }}"
          until: _async_status.finished
          retries: 100
          delay: 5

    # Deploy Sushy Emulator on the Ansible controller,
    - name: Deploy Sushy Emulator service container
      tags:
        - bootstrap
        - bootstrap_layout
      when: cifmw_use_sushy_emulator | default(true) | bool
      block:
        - name: Deploy Sushy Emulator
          vars:
            cifmw_sushy_emulator_hypervisor_target: "{{ cifmw_target_host | default('localhost') }}"
            cifmw_sushy_emulator_install_type: podman
            cifmw_sushy_emulator_hypervisor_target_connection_ip: "{{ network_bridge_info['cifmw-public'] }}"
          ansible.builtin.include_role:
            name: sushy_emulator

        - name: Let the project know we have Sushy Emulator available
          ansible.builtin.set_fact:
            _sushy_emulator_available: true

    - name: Generate baremetal-info fact
      ansible.builtin.import_tasks: generate_bm_info.yml

    - name: Verify connection to baremetal VMs via Sushy Emulator
      when: _sushy_emulator_available | default(false)
      ansible.builtin.include_role:
        name: sushy_emulator
        tasks_from: verify.yml

    - name: Install ansible dependencies
      ansible.builtin.pip:
        requirements: https://raw.githubusercontent.com/openstack-k8s-operators/ci-framework/main/common-requirements.txt

    - name: Inject most of the cifmw_ parameters passed to the reproducer run
      tags:
        - bootstrap_env
      vars:
        _filtered_vars: >-
          {{
            hostvars[inventory_hostname] | default({}) |
            dict2items |
            selectattr('key', 'match',
                       '^(pre|post|cifmw)_(?!install_yamls|devscripts).*') |
            rejectattr('key', 'equalto', 'cifmw_target_host') |
            rejectattr('key', 'equalto', 'cifmw_basedir') |
            rejectattr('key', 'equalto', 'cifmw_path') |
            rejectattr('key', 'equalto', 'cifmw_extras') |
            rejectattr('key', 'equalto', 'cifmw_openshift_kubeconfig') |
            rejectattr('key', 'equalto', 'cifmw_openshift_token') |
            rejectattr('key', 'equalto', 'cifmw_set_openstack_containers_registry') |
            rejectattr('key', 'match', '^cifmw_use_(?!lvms).*') |
            rejectattr('key', 'match', '^cifmw_reproducer.*') |
            rejectattr('key', 'match', '^cifmw_rhol.*') |
            rejectattr('key', 'match', '^cifmw_discover.*') |
            rejectattr('key', 'match', '^cifmw_libvirt_manager.*') |
            rejectattr('key', 'match', '^cifmw_manage_secrets_(pullsecret|citoken).*') |
            items2dict
          }}
      ansible.builtin.copy:
        dest: "/home/zuul/ci-framework-data/parameters/reproducer-variables.yml"
        content: "{{ _filtered_vars | to_nice_yaml }}"

    - name: Create reproducer-variables.yml symlink to old location
      ansible.builtin.file:
        dest: "/home/zuul/reproducer-variables.yml"
        src: "/home/zuul/ci-framework-data/parameters/reproducer-variables.yml"
        state: link

    - name: Inject local environment parameters
      ansible.builtin.copy:
        dest: "/home/zuul/ci-framework-data/parameters/openshift-environment.yml"
        content: |-
          {% raw %}
          ---
          cifmw_basedir: "{{ ansible_user_dir }}/ci-framework-data"
          cifmw_openshift_login_password_file: >-
            {{ ansible_user_dir }}/.kube/kubeadmin-password
          cifmw_openshift_login_kubeconfig: >-
            {{ ansible_user_dir }}/.kube/config
          cifmw_architecture_automation_file: >-
            {{
              (
                cifmw_architecture_repo | default(ansible_user_dir+'/src/github.com/openstack-k8s-operators/architecture'),
                'automation/vars',
                cifmw_arch_automation_file | default('default.yaml')
              ) | ansible.builtin.path_join
            }}
          {% endraw %}

    - name: Create openshift-environment.yml symlink to old location
      ansible.builtin.file:
        dest: "/home/zuul/openshift-environment.yml"
        src: "/home/zuul/ci-framework-data/parameters/openshift-environment.yml"
        state: link

    - name: Get interfaces-info content
      register: _nic_info
      ansible.builtin.slurp:
        src: "{{ _ctl_reproducer_basedir }}/parameters/interfaces-info.yml"

    # We detected OCP cluster may have some downtime even after it's supposed
    # to be started.
    # It means everything was right from the libvirt_manager point of view, it
    # could get access, configure the needed bits and move on.
    # But when we hit this step, cluster may be unresponsive - suspecting
    # some NetworkManager or related tool doing some "late" tasks.
    # This task here is to ensure all of the OCPs nodes are ready to be
    # consumed by the networking_mapper - it will connect to all of the nodes
    # in order to gather some facts of interest.
    - name: Wait for OCP nodes to be ready
      when:
        - groups.ocps is defined
      delegate_to: "{{ item }}"
      ansible.builtin.wait_for_connection:
        sleep: 2
        timeout: 300
      loop: "{{ groups.ocps }}"

    - name: Generate networking definition
      vars:
        cifmw_networking_mapper_ifaces_info: >-
          {{ _nic_info.content | b64decode | from_yaml }}
        cifmw_networking_mapper_network_name: >-
          {{ _cifmw_libvirt_manager_layout.vms.controller.nets.1 }}
        cifmw_networking_mapper_basedir: "/home/zuul/ci-framework-data"
      ansible.builtin.import_role:
        name: networking_mapper

    - name: Configure ctlplane interface on controller-0
      become: true
      vars:
        _ctlplane_net: "{{ cifmw_networking_env_definition.networks.ctlplane }}"
        _controller_data: "{{ cifmw_networking_env_definition.instances['controller-0'].networks.ctlplane}}"
        _prefix: "{{ _ctlplane_net.network_v4 | ansible.utils.ipaddr('prefix') }}"
      community.general.nmcli:
        autoconnect: true
        conn_name: ctlplane
        dns4: "{{ _ctlplane_net.dns_v4.0 }}"
        ifname: "{{ _controller_data.interface_name }}"
        type: ethernet
        ip4: "{{ _controller_data.ip_v4 }}/{{ _prefix }}"
        never_default4: true
        state: present

    - name: Inject CRC related content if needed
      when:
        - _cifmw_libvirt_manager_layout.vms.crc is defined
        - (_cifmw_libvirt_manager_layout.vms.crc.amount is defined and
           (_cifmw_libvirt_manager_layout.vms.crc.amount | int ) > 0) or
          _cifmw_libvirt_manager_layout.vms.crc.amount is undefined
      block:
        - name: Inject CRC ssh key
          ansible.builtin.copy:
            dest: "/home/zuul/.ssh/crc_key"
            content: "{{ crc_priv_key['content'] | b64decode }}"
            mode: "0400"
            owner: zuul
            group: zuul

        - name: Inject crc related host entry
          become: true
          vars:
            _crc_data: "{{ cifmw_networking_env_definition.instances['crc-0'].networks.ctlplane}}"
          ansible.builtin.lineinfile:
            path: /etc/hosts
            line: >-
              {{ _crc_data.ip_v4 }} api.crc.testing
              canary-openshift-ingress-canary.apps-crc.testing
              console-openshift-console.apps-crc.testing
              default-route-openshift-image-registry.apps-crc.testing
              downloads-openshift-console.apps-crc.testing
              oauth-openshift.apps-crc.testing
