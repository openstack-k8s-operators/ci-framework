---
# This is local to your desktop/laptop.
# We can only use ansible_user_dir if you have the same user on the hypervisor
# and locally - otherwise edit this
cifmw_install_yamls_repo: "{{ ansible_user_dir }}/src/github.com/openstack-k8s-operators/install_yamls"
# This will be created on the hypervisor.
cifmw_basedir: "{{ ansible_user_dir }}/ci-framework-data"
cifmw_path: "{{ ansible_user_dir }}/bin:{{ ansible_env.PATH }}"

cifmw_reproducer_epel_pkgs:
  - python3-bcrypt
  - python3-passlib

cifmw_libvirt_manager_pub_net: ocpbm

# Automation section. Most of those parameters will be passed to the
# controller-0 as-is and be consumed by the `deploy-va.sh` script.
# Please note, all paths are on the controller-0, meaning managed by the
# Framework. Please do not edit them!
_arch_repo: "/home/zuul/src/github.com/openstack-k8s-operators/architecture"
cifmw_architecture_scenario: "ovs-dpdk-sriov"

# HERE if you want to overload kustomization, you can uncomment this parameter
# and push the data structure you want to apply.
# cifmw_architecture_user_kustomize:
#   stage_0:
#     'network-values':
#       data:
#         starwars: Obiwan

# HERE, if you want to stop the deployment loop at any stage, you can uncomment
# the following parameter and update the value to match the stage you want to
# reach. Known stages are:
#   pre_kustomize_stage_INDEX
#   pre_apply_stage_INDEX
#   post_apply_stage_INDEX
#
# cifmw_deploy_architecture_stopper:

# What about some tempest?
cifmw_run_tests: true
cifmw_run_tempest: true
cifmw_run_test_role: test_operator
cifmw_test_operator_timeout: 7200
cifmw_test_operator_tempest_include_list: |
  tempest.scenario.test_network_basic_ops.TestNetworkBasicOps

# This will instruct libvirt_manager to create
# the ansible-controller, consuming the networks created and
# managed by devscripts.
# Note that the "osp_trunk" network is the equivalent of the
# "private_net" in the CI layout, and will hold the VLAN for
# network isolation.
# The "ocpbm" network is managed by devscripts as well, and
# provides access to Internet. This will be the equivalent of the
# "public network" as seen in CI.
cifmw_use_libvirt: true
cifmw_use_uefi: >-
  {{ (cifmw_repo_setup_os_release is defined
      and cifmw_repo_setup_os_release == 'rhel') | bool }}
cifmw_root_partition_id: >-
  {{
    (cifmw_repo_setup_os_release is defined and cifmw_repo_setup_os_release == 'rhel') |
    ternary(4, 1)
  }}
cifmw_libvirt_manager_net_prefix_add: false
cifmw_libvirt_manager_fixed_networks:
  - ocpbm
  - ocppr
  - osp_external
  - osp_trunk
cifmw_libvirt_manager_configuration:
  networks:
    ocpbm: |
      <network>
        <name>ocpbm</name>
        <forward mode='bridge' />
        <bridge name='ocpbm' />
      </network>
    ocppr: |
      <network>
        <name>ocppr</name>
        <forward mode='bridge' />
        <bridge name='ocppr' />
      </network>
    osp_external: |
      <network>
        <name>osp_external</name>
        <forward mode='bridge' />
        <bridge name='osp_external' />
      </network>
    osp_trunk: |
      <network>
        <name>osp_trunk</name>
        <forward mode='bridge' />
        <bridge name='osp_trunk' />
      </network>
  vms:
    controller:
      uefi: "{{ cifmw_use_uefi }}"
      root_part_id: "{{ cifmw_root_partition_id }}"
      image_url: "{{ cifmw_discovered_image_url }}"
      sha256_image_name: "{{ cifmw_discovered_hash }}"
      image_local_dir: "{{ cifmw_basedir }}/images/"
      disk_file_name: "base-os.qcow2"
      disksize: 50
      memory: 8
      cpus: 4
      nets:
        - ocpbm
        - osp_trunk
    ocp:
      amount: 3
      admin_user: core
      image_local_dir: "/home/dev-scripts/pool"
      disk_file_name: "ocp_master"
      disksize: "105"
      xml_paths:
        - /home/dev-scripts/ocp_master_0.xml
        - /home/dev-scripts/ocp_master_1.xml
        - /home/dev-scripts/ocp_master_2.xml
      nets:
        - osp_trunk
        - osp_external

## devscript support for OCP deploy
cifmw_use_devscripts: true
# Required for egress traffic from pods to the osp_trunk network
cifmw_devscripts_enable_ocp_nodes_host_routing: true

# Note: with that extra_network_names "osp_trunk", we instruct
# devscripts role to create a new network, and associate it to
# the OCP nodes. This one is a "private network", and will hold
# the VLANs used for network isolation.

# Please create a custom env file to provide:
# cifmw_devscripts_ci_token:
# cifmw_devscripts_pull_secret:

# type and size of ssh keys injected into the OCP workers and compute nodes
cifmw_ssh_keytype: ecdsa
cifmw_ssh_keysize: 521

# Baremetal host configuration
cifmw_config_bmh: true
cimfw_deploy_bmh_root_device_hint_field: "wwnWithExtension"
