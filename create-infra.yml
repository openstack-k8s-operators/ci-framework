---
# Purpose of this playbook:
# - Create a virtual infrastructure consisting in
#   virtual machines, related storage, and virtual networks.
#
# - Create a dnsmasq instance with the appropriate records to provide
#   fixed IPs, proper DNS resolution
#
# - Expose at least one inventory file showing the various resources
#
# This playbook is meant to run for architecture driven deployment only.

- name: Parent scenario if needed
  hosts: "{{ cifmw_target_host | default('localhost') }}"
  gather_facts: true
  tasks:
    - name: Inherit from parent scenarios if needed
      ansible.builtin.include_tasks:
        file: "ci/playbooks/tasks/inherit_parent_scenario.yml"

- name: Manage/generate unique ID
  ansible.builtin.import_playbook: playbooks/unique-id.yml

- name: Run consistency checks
  ansible.builtin.import_playbook: "playbooks/adoption/pre.yml"

- name: Prepare infrastructure datasets
  ansible.builtin.import_playbook: "playbooks/adoption/infra.yml"

- name: Amend infrastructure datasets
  hosts: "{{ cifmw_target_host | default('localhost') }}"
  gather_facts: true
  tasks:
    # Inject "start: false" in the layout to not start any VM yet.
    # Starting the VM will be done later, either by the tool deploying
    # OSP, or the one deploy RHOSO.
    # VM initial configuration, when managed, is done using cloud-init.
    - name: Ensure no VM is started when we create them during this run
      vars:
        _no_start: >-
          {% set _vms = {}                                          -%}
          {% for _type in _cifmw_libvirt_manager_layout.vms.keys()  -%}
          {%   set _ = _vms.update({_type: {'start': false}})       -%}
          {% endfor                                                 -%}
          {{ _vms }}
      ansible.builtin.set_fact:
        _cifmw_libvirt_manager_layout: >-
          {{
            _cifmw_libvirt_manager_layout |
            combine({'vms': _no_start}, recursive=true)
          }}
    - name: Set amount for OCP cluster members to 0
      vars:
        _0_ocp:
          vms:
            ocp:
              amount: 0
            ocp_worker:
              amount: 0
      ansible.builtin.set_fact:
        _cifmw_libvirt_manager_layout: >-
          {{
            _cifmw_libvirt_manager_layout | combine(_0_ocp, recursive=true)
          }}

- name: Prepare networking
  ansible.builtin.import_playbook: "playbooks/adoption/network.yml"

- name: Deploy infrastructure
  hosts: "{{ cifmw_target_host | default('localhost') }}"
  gather_facts: true
  tasks:
    # Create all the VMs
    - name: Deploy layout
      ansible.builtin.import_role:
        name: "libvirt_manager"
        tasks_from: "deploy_layout.yml"

    - name: Gather ansible_user_id
      ansible.builtin.setup:
        gather_subset:
          - user_id
          - user_dir

    - name: Ensure controllers vms are started and reachable
      when: groups.controllers | default([]) | length > 0
      vars:
        _cifmw_libvirt_manager_layout:
          vms:
            controllers:
              start: true
              disk_file_name: "dummy"
        cifmw_libvirt_manager_all_vms: >-
          {%- set vms = {} -%}
          {%- for vm in groups.controllers | default([]) -%}
            {%- set _ = vms.update({vm: 'controllers'}) -%}
          {%- endfor -%}
          {{ vms }}
        ansible_libvirt_pools: {}
      ansible.builtin.include_role:
        name: "libvirt_manager"
        tasks_from: "start_vms.yml"
        apply:
          delegate_to: "{{ cifmw_target_host | default('localhost') }}"

    # This bootstraps the controller-0 node, and RedFish virtual BMC is
    # spawned if cifmw_use_sushy_emulator is enabled.
    - name: Bootstrap sushy-emulator (RedFish Virtual BMC) on controller-0
      when:
        - "'controllers' in groups"
        - cifmw_use_sushy_emulator | default(false) | bool
      delegate_to: controller-0
      become: true
      vars:
        cifmw_sushy_emulator_hypervisor_target: "{{ cifmw_target_host }}"
        cifmw_sushy_emulator_hypervisor_address: "{{ cifmw_target_host }}.utility"
        cifmw_sushy_emulator_install_type: podman
        cifmw_podman_user_linger: "zuul"
      block:
        - name: Run reproducer roles rhos_release tasks on controller-0
          ansible.builtin.include_role:
            name: reproducer
            tasks_from: rhos_release.yml

        - name: Include role sushy_emulator
          ansible.builtin.include_role:
            name: sushy_emulator

        - name: Generate baremetal-info fact
          vars:
            cifmw_sushy_emulator_uri: 'http://sushy.utility:8000'
          ansible.builtin.include_role:
            name: reproducer
            tasks_from: generate_bm_info.yml

        - name: Verify connection to baremetal VMs via Sushy Emulator
          ansible.builtin.include_role:
            name: sushy_emulator
            tasks_from: verify.yml

        - name: Set permissions on /home/zuul/ci-framework-data on controller-0
          ansible.builtin.file:
            path: "{{ cifmw_basedir | default('/home/zuul/ci-framework-data') }}"
            state: directory
            recurse: true
            owner: zuul
            group: zuul
            mode: "0755"
