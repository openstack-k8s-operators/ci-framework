---
# Copyright 2023 Red Hat, Inc.
# All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.

- name: Create local SSH keypair
  tags: keypair
  hosts: localhost
  gather_facts: false
  vars:
    cifmw_admin_user: ceph-admin
  tasks:
    - name: Set ssh key path facts
      ansible.builtin.set_fact:
        private_key: "{{ lookup('env', 'HOME') }}/.ssh/{{ cifmw_admin_user }}-id_rsa"
        public_key: "{{ lookup('env', 'HOME') }}/.ssh/{{ cifmw_admin_user }}-id_rsa.pub"
      run_once: true  # noqa: run-once[task]

    - name: Stat private key
      ansible.builtin.stat:
        path: "{{ private_key }}"
      register: private_key_stat

    - name: Stat public key
      ansible.builtin.stat:
        path: "{{ public_key }}"
      register: public_key_stat

    - name: Create private key if it does not exist
      ansible.builtin.command:
        cmd: "ssh-keygen -t rsa -q -N '' -f {{ private_key }}"
      no_log: true
      when:
        - not private_key_stat.stat.exists

    - name: Create public key if it does not exist
      ansible.builtin.shell: "ssh-keygen -y -f {{ private_key }} > {{ public_key }}"
      when:
        - not public_key_stat.stat.exists

- name: Distribute SSH keypair to EDPM nodes
  tags: admin
  hosts: edpm
  gather_facts: false
  become: true
  vars:
    ansible_ssh_private_key_file: "{{ lookup('env', 'ANSIBLE_SSH_PRIVATE_KEY') }}"
  pre_tasks:
    - name: Get local private key
      ansible.builtin.slurp:
        src: "{{ hostvars['localhost']['private_key'] }}"
      register: private_key_get
      delegate_to: localhost
      no_log: true

    - name: Get local public key
      ansible.builtin.slurp:
        src: "{{ hostvars['localhost']['public_key'] }}"
      register: public_key_get
      delegate_to: localhost
  roles:
    - role: cifmw_create_admin
      cifmw_admin_user: ceph-admin
      cifmw_admin_pubkey: "{{ public_key_get['content'] | b64decode }}"
      cifmw_admin_prikey: "{{ private_key_get['content'] | b64decode }}"
      cifmw_admin_distribute_private_key: true
      no_log: true

- name: Create Block Device on EDPM Nodes
  tags: block
  hosts: edpm
  gather_facts: true
  become: true
  vars:
    ansible_ssh_private_key_file: "{{ lookup('env', 'ANSIBLE_SSH_PRIVATE_KEY') }}"
  roles:
    - role: cifmw_block_device

- name: Build Ceph spec from gathered IP addresses of EDPM inventory group
  tags: spec
  hosts: localhost
  gather_facts: true
  vars:
    # storage_network_range: 172.18.0.0/24
    storage_network_range: 192.168.122.0/24
    all_addresses: ansible_all_ipv4_addresses # change if you need IPv6
  pre_tasks:
    - name: Build a dict mapping hostname to its IP which is in storage network range
      ansible.builtin.set_fact:
        host_to_ip: >-
          {{ host_to_ip | default({}) | combine({hostvars['ansible_hostname']: hostvars | ipaddr(storage_network_range) | first}) }}
      delegate_to: "{{ item }}"
      loop: "{{ groups['edpm'] }}"
  roles:
    - role: cifmw_ceph_spec
      cifmw_ceph_spec_host_to_ip: "{{ host_to_ip }}"
      cifmw_ceph_spec_public_network: "{{ storage_network_range }}"

- name: Bootstrap Ceph and apply spec
  tags: cephadm
  hosts: edpm[0]
  gather_facts: false
  vars:
    ansible_ssh_private_key_file: "{{ lookup('env', 'ANSIBLE_SSH_PRIVATE_KEY') }}"
    cifmw_cephadm_spec_ansible_host: /tmp/ceph_spec.yml
    cifmw_cephadm_bootstrap_conf: /tmp/initial_ceph.conf
    cifmw_ceph_client_vars: /tmp/ceph_client.yml
    cifmw_cephadm_bootstrap_host: "{{ ansible_hostname }}"
    cifmw_cephadm_default_container: true
    all_addresses: ansible_all_ipv4_addresses # change if you need IPv6
    cifmw_cephadm_pools:
      - name: vms
        pg_autoscale_mode: true
        target_size_ratio: 0.3
        application: rbd
      - name: volumes
        pg_autoscale_mode: true
        target_size_ratio: 0.3
        application: rbd
      - name: backups
        pg_autoscale_mode: true
        target_size_ratio: 0.2
        application: rbd
      - name: images
        target_size_ratio: 0.2
        pg_autoscale_mode: true
        application: rbd
  pre_tasks:
    - name: Generate a cephx key
      cephx_key:
      register: cephx
      no_log: true

    - name: Set cifmw_cephadm_keys with the cephx key and cifmw_cephadm_pools
      ansible.builtin.set_fact:
        cifmw_cephadm_keys:
          - name: client.openstack
            key: "{{ cephx.key }}"
            mode: '0600'
            caps:
              mgr: allow *
              mon: profile rbd
              osd: "{{ pools | map('regex_replace', '^(.*)$',
                                   'profile rbd pool=\\1') | join(', ') }}"
      vars:
        pools: "{{ cifmw_cephadm_pools | map(attribute='name') | list }}"
      no_log: true

    - name: Set IP address of first monitor
      ansible.builtin.set_fact:
        cifmw_cephadm_first_mon_ip: "{{ item.addr }}"
      when:
        - item.service_type == 'host'
        - item.hostname == "{{ cifmw_cephadm_bootstrap_host }}"  # noqa: no-jinja-when
      loop: "{{ lookup('file', cifmw_cephadm_spec_ansible_host) | from_yaml_all | list }}"
      delegate_to: localhost

    # public network always exist because is provided by the ceph_spec role
    - name: Get Storage network range
      ansible.builtin.set_fact:
        cifmw_cephadm_rgw_network: "{{ lookup('ansible.builtin.ini', 'public_network section=global file=' ~ cifmw_cephadm_bootstrap_conf) }}"

    - name: Get already assigned IP addresses
      ansible.builtin.set_fact:
        ips: "{{ ips | default([]) + [ hostvars[item][all_addresses] | ipaddr(cifmw_cephadm_rgw_network) | first ] }}"
      loop: "{{ groups['edpm'] }}"

    # cifmw_cephadm_vip is the VIP reserved in the Storage network
    - name: Set VIP var as empty string
      ansible.builtin.set_fact:
        cifmw_cephadm_vip: ""

    - name: Process VIP
      ansible.builtin.include_role:
        name: cifmw_cephadm
        tasks_from: check_vip
      loop: "{{ range(1, (ips | length) + 1) | list }}"

  tasks:
    - name: Satisfy Ceph prerequisites
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: pre

    - name: Bootstrap Ceph
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: bootstrap

    - name: Apply Ceph spec
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: apply_spec

    - name: Create ceph pools
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: pools

    - name: Deploy RGW
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: rgw
      vars:
        # cifmw_cephadm_vip is computed or passed as an override via -e @extra.yml
        cifmw_cephadm_rgw_vip: "{{ cifmw_cephadm_vip }}/24"

    - name: Create Cephx Keys for OpenStack
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: keys

    - name: Export configuration as vars for cifmw_ceph_client
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: export

    - name: Show the Ceph cluster status
      ansible.builtin.import_role:
        name: cifmw_cephadm
        tasks_from: post

- name: Render Ceph client configuration
  tags: client
  hosts: localhost
  gather_facts: false
  vars:
    cifmw_ceph_client_vars: /tmp/ceph_client.yml
    cifmw_ceph_client_fetch_dir: /tmp
    cifmw_ceph_client_k8s_secret_name: ceph-conf-files
    cifmw_ceph_client_k8s_namespace: openstack
  tasks:
    - name: Export configuration for ceph client
      ansible.builtin.import_role:
        name: cifmw_ceph_client
    - name: Output usage
      ansible.builtin.debug:
        msg: >-
          Import ceph secret into k8s
          'kubectl create -f /tmp/k8s_ceph_secret.yml'
